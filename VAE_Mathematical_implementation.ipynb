{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPA//YO/9uM14vSwhJl/ZQ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorrespz/Generative-models/blob/main/VAE_Mathematical_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Autoencoder from scratch\n",
        "\n",
        "This notebook is from the following repo\n",
        "\n",
        "https://github.com/jmtomczak/intro_dgm/blob/main/vaes/\n",
        "\n",
        "This notebook implements the following mathematical procedure: For a given dataset $D = \\{x_n\\}^N_{n=1}$, to generate the distribution of $D$, there are 4 steps:\n",
        "  -  Take $x_n$ and apply the encoder network to get $\\mu_\\phi(x_n)$ and $\\ln\\sigma_{\\phi}(x_n)$.\n",
        "  -  Calculate $z_{\\phi ,n}$ by applying the reparameterization trick, $z_{\\phi,n} = \\mu_\\phi(x_n) + \\sigma_\\phi(x_n) \\odot \\epsilon$,where $\\epsilon \\sim N(0,I)$.\n",
        "  - Apply the decoder network to $z_{\\phi,n}$ to get the probabilities $\\theta(z_{\\phi,n})$.\n",
        "  -  Calculate the objective function ELBO  by plugging in $x_n,z_{\\phi,n},\\mu_\\phi(x_n), \\ln\\sigma_{\\phi}(x_n)$.\n",
        "\n",
        "In terms of neural networks, we have the following:\n",
        "  -  The encoder network:\n",
        "$x \\in X^D  \\rightarrow Linear(D, 256) \\rightarrow LeakyReLU \\rightarrow\n",
        "Linear(256,2M) \\rightarrow split \\rightarrow \\mu \\in R^M, log\\sigma^2 \\in R^M.$\n",
        "  - The decoder network:\n",
        "$z \\in R^M  \\rightarrow  Linear(M, 256) \\rightarrow  LeakyReLU \\rightarrow\n",
        "Linear(256, D \\times L) \\rightarrow  reshape \\rightarrow  softmax \\rightarrow  \\theta \\in [0, 1]^{D\\times L}$"
      ],
      "metadata": {
        "id": "muxcOtOMLh7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JM-UJESNKdxG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pytorch-model-summary"
      ],
      "metadata": {
        "id": "Jd7eJZdbLUDW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pytorch_model_summary import summary"
      ],
      "metadata": {
        "id": "dYVxHpN9LXxL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "JS2jecXoL3Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Digits(Dataset):\n",
        "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, mode='train', transforms=None):\n",
        "        digits = load_digits()\n",
        "        if mode == 'train':\n",
        "            self.data = digits.data[:1000].astype(np.float32)\n",
        "        elif mode == 'val':\n",
        "            self.data = digits.data[1000:1350].astype(np.float32)\n",
        "        else:\n",
        "            self.data = digits.data[1350:].astype(np.float32)\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(sample)\n",
        "        return sample"
      ],
      "metadata": {
        "id": "Om85so3TLCdz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define probability distributions"
      ],
      "metadata": {
        "id": "mFPwPMzvMFHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PI = torch.from_numpy(np.asarray(np.pi))\n",
        "EPS = 1.e-5\n",
        "\n",
        "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
        "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "def log_bernoulli(x, p, reduction=None, dim=None):\n",
        "    pp = torch.clamp(p, EPS, 1. - EPS)\n",
        "    log_p = x * torch.log(pp) + (1. - x) * torch.log(1. - pp)\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "\n",
        "def log_standard_normal(x, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p"
      ],
      "metadata": {
        "id": "2Cz8W9j4LYpR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "6jNbMHk5PSmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoder_net):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.encoder = encoder_net\n",
        "\n",
        "    @staticmethod\n",
        "    def reparameterization(mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "\n",
        "        eps = torch.randn_like(std)\n",
        "\n",
        "        return mu + std * eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        h_e = self.encoder(x)\n",
        "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
        "\n",
        "        return mu_e, log_var_e\n",
        "\n",
        "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
        "        if (mu_e is None) and (log_var_e is None):\n",
        "            mu_e, log_var_e = self.encode(x)\n",
        "        else:\n",
        "            if (mu_e is None) or (log_var_e is None):\n",
        "                raise ValueError('mu and log-var can`t be None!')\n",
        "        z = self.reparameterization(mu_e, log_var_e)\n",
        "        return z\n",
        "\n",
        "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
        "        if x is not None:\n",
        "            mu_e, log_var_e = self.encode(x)\n",
        "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
        "        else:\n",
        "            if (mu_e is None) or (log_var_e is None) or (z is None):\n",
        "                raise ValueError('mu, log-var and z can`t be None!')\n",
        "\n",
        "        return log_normal_diag(z, mu_e, log_var_e)\n",
        "\n",
        "    def forward(self, x, type='log_prob'):\n",
        "        assert type in ['encode', 'log_prob'], 'Type could be either encode or log_prob'\n",
        "        if type == 'log_prob':\n",
        "            return self.log_prob(x)\n",
        "        else:\n",
        "            return self.sample(x)"
      ],
      "metadata": {
        "id": "hdxQ-KxhO9MX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "pXtQCZjpPadZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, decoder_net, distribution='categorical', num_vals=None):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.decoder = decoder_net\n",
        "        self.distribution = distribution\n",
        "        self.num_vals=num_vals\n",
        "\n",
        "    def decode(self, z):\n",
        "        h_d = self.decoder(z)\n",
        "\n",
        "        if self.distribution == 'categorical':\n",
        "            b = h_d.shape[0]\n",
        "            d = h_d.shape[1]//self.num_vals\n",
        "            h_d = h_d.view(b, d, self.num_vals)\n",
        "            mu_d = torch.softmax(h_d, 2)\n",
        "            return [mu_d]\n",
        "\n",
        "        elif self.distribution == 'bernoulli':\n",
        "            mu_d = torch.sigmoid(h_d)\n",
        "            return [mu_d]\n",
        "\n",
        "        else:\n",
        "            raise ValueError('Either `categorical` or `bernoulli`')\n",
        "\n",
        "    def sample(self, z):\n",
        "        outs = self.decode(z)\n",
        "\n",
        "        if self.distribution == 'categorical':\n",
        "            mu_d = outs[0]\n",
        "            b = mu_d.shape[0]\n",
        "            m = mu_d.shape[1]\n",
        "            mu_d = mu_d.view(mu_d.shape[0], -1, self.num_vals)\n",
        "            p = mu_d.view(-1, self.num_vals)\n",
        "            x_new = torch.multinomial(p, num_samples=1).view(b, m)\n",
        "\n",
        "        elif self.distribution == 'bernoulli':\n",
        "            mu_d = outs[0]\n",
        "            x_new = torch.bernoulli(mu_d)\n",
        "\n",
        "        else:\n",
        "            raise ValueError('Either `categorical` or `bernoulli`')\n",
        "\n",
        "        return x_new\n",
        "\n",
        "    def log_prob(self, x, z):\n",
        "        outs = self.decode(z)\n",
        "\n",
        "        if self.distribution == 'categorical':\n",
        "            mu_d = outs[0]\n",
        "            log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
        "\n",
        "        elif self.distribution == 'bernoulli':\n",
        "            mu_d = outs[0]\n",
        "            log_p = log_bernoulli(x, mu_d, reduction='sum', dim=-1)\n",
        "\n",
        "        else:\n",
        "            raise ValueError('Either `categorical` or `bernoulli`')\n",
        "\n",
        "        return log_p\n",
        "\n",
        "    def forward(self, z, x=None, type='log_prob'):\n",
        "        assert type in ['decoder', 'log_prob'], 'Type could be either decode or log_prob'\n",
        "        if type == 'log_prob':\n",
        "            return self.log_prob(x, z)\n",
        "        else:\n",
        "            return self.sample(z)"
      ],
      "metadata": {
        "id": "dU4NoKM1PUTr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prior"
      ],
      "metadata": {
        "id": "AG-Vhz3APdhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Prior(nn.Module):\n",
        "    def __init__(self, L):\n",
        "        super(Prior, self).__init__()\n",
        "        self.L = L\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        z = torch.randn((batch_size, self.L))\n",
        "        return z\n",
        "\n",
        "    def log_prob(self, z):\n",
        "        return log_standard_normal(z)"
      ],
      "metadata": {
        "id": "kWVLVz2TPbYE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full VAE"
      ],
      "metadata": {
        "id": "dOYkQeUzPpoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, encoder_net, decoder_net, num_vals=256, L=16, likelihood_type='categorical'):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(encoder_net=encoder_net)\n",
        "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net, num_vals=num_vals)\n",
        "        self.prior = Prior(L=L)\n",
        "\n",
        "        self.num_vals = num_vals\n",
        "        self.likelihood_type = likelihood_type\n",
        "\n",
        "    def forward(self, x, reduction='avg'):\n",
        "        # encoder\n",
        "        mu_e, log_var_e = self.encoder.encode(x)\n",
        "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
        "\n",
        "        # ELBO\n",
        "        RE = self.decoder.log_prob(x, z)\n",
        "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
        "\n",
        "        if reduction == 'sum':\n",
        "            return -(RE + KL).sum()\n",
        "        else:\n",
        "            return -(RE + KL).mean()\n",
        "\n",
        "    def sample(self, batch_size=64):\n",
        "        z = self.prior.sample(batch_size=batch_size)\n",
        "        return self.decoder.sample(z)"
      ],
      "metadata": {
        "id": "iyEG7Do4PeZg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility functions"
      ],
      "metadata": {
        "id": "S86F_lrGR2rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
        "    # EVALUATION\n",
        "    if model_best is None:\n",
        "        # load best performing model\n",
        "        model_best = torch.load(name + '.model')\n",
        "\n",
        "    model_best.eval()\n",
        "    loss = 0.\n",
        "    N = 0.\n",
        "    for indx_batch, test_batch in enumerate(test_loader):\n",
        "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
        "        loss = loss + loss_t.item()\n",
        "        N = N + test_batch.shape[0]\n",
        "    loss = loss / N\n",
        "\n",
        "    if epoch is None:\n",
        "        print(f'FINAL LOSS: nll={loss}')\n",
        "    else:\n",
        "        print(f'Epoch: {epoch}, val nll={loss}')\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def samples_real(name, test_loader):\n",
        "    # REAL-------\n",
        "    num_x = 4\n",
        "    num_y = 4\n",
        "    x = next(iter(test_loader)).detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(num_x, num_y)\n",
        "    for i, ax in enumerate(ax.flatten()):\n",
        "        plottable_image = np.reshape(x[i], (8, 8))\n",
        "        ax.imshow(plottable_image, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def samples_generated(name, data_loader, extra_name=''):\n",
        "    x = next(iter(data_loader)).detach().numpy()\n",
        "\n",
        "    # GENERATIONS-------\n",
        "    model_best = torch.load(name + '.model')\n",
        "    model_best.eval()\n",
        "\n",
        "    num_x = 4\n",
        "    num_y = 4\n",
        "    x = model_best.sample(num_x * num_y)\n",
        "    x = x.detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(num_x, num_y)\n",
        "    for i, ax in enumerate(ax.flatten()):\n",
        "        plottable_image = np.reshape(x[i], (8, 8))\n",
        "        ax.imshow(plottable_image, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_curve(name, nll_val):\n",
        "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('nll')\n",
        "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "YFYua9AePtJ0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
        "    nll_val = []\n",
        "    best_nll = 1000.\n",
        "    patience = 0\n",
        "\n",
        "    # Main loop\n",
        "    for e in range(num_epochs):\n",
        "        # TRAINING\n",
        "        model.train()\n",
        "        for indx_batch, batch in enumerate(training_loader):\n",
        "            if hasattr(model, 'dequantization'):\n",
        "                if model.dequantization:\n",
        "                    batch = batch + torch.rand(batch.shape)\n",
        "            loss = model.forward(batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
        "        nll_val.append(loss_val)  # save for plotting\n",
        "\n",
        "        if e == 0:\n",
        "            print('saved!')\n",
        "            torch.save(model, name + '.model')\n",
        "            best_nll = loss_val\n",
        "        else:\n",
        "            if loss_val < best_nll:\n",
        "                print('saved!')\n",
        "                torch.save(model, name + '.model')\n",
        "                best_nll = loss_val\n",
        "                patience = 0\n",
        "\n",
        "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
        "            else:\n",
        "                patience = patience + 1\n",
        "\n",
        "        if patience > max_patience:\n",
        "            break\n",
        "\n",
        "    nll_val = np.asarray(nll_val)\n",
        "\n",
        "    return nll_val"
      ],
      "metadata": {
        "id": "KR7ZnXleR4vQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize dataloaders and define parameters"
      ],
      "metadata": {
        "id": "_BKxFJ5ASFPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Digits(mode='train')\n",
        "val_data = Digits(mode='val')\n",
        "test_data = Digits(mode='test')\n",
        "\n",
        "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "result_dir = 'results/'\n",
        "if not(os.path.exists(result_dir)):\n",
        "    os.mkdir(result_dir)\n",
        "name = 'vae'"
      ],
      "metadata": {
        "id": "V_ggGQWcSCR3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPm0jDtXSJ2z",
        "outputId": "a49d8da3-2aa9-4cf5-9389-320292cae37e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = 64   # input dimension\n",
        "L = 16  # number of latents\n",
        "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
        "\n",
        "lr = 1e-3 # learning rate\n",
        "num_epochs = 1000 # max. number of epochs\n",
        "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
      ],
      "metadata": {
        "id": "AAUL1p1ISLBg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "likelihood_type = 'categorical'\n",
        "\n",
        "if likelihood_type == 'categorical':\n",
        "    num_vals = 17\n",
        "elif likelihood_type == 'bernoulli':\n",
        "    num_vals = 1\n",
        "\n",
        "encoder = nn.Sequential(nn.Linear(D, M), nn.LeakyReLU(),\n",
        "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
        "                        nn.Linear(M, 2 * L))\n",
        "\n",
        "decoder = nn.Sequential(nn.Linear(L, M), nn.LeakyReLU(),\n",
        "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
        "                        nn.Linear(M, num_vals * D))\n",
        "\n",
        "prior = torch.distributions.MultivariateNormal(torch.zeros(L), torch.eye(L))\n",
        "model = VAE(encoder_net=encoder, decoder_net=decoder, num_vals=num_vals, L=L, likelihood_type=likelihood_type)"
      ],
      "metadata": {
        "id": "x5UjtmT8SPzF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "jWkHEuctSs9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIMIZER\n",
        "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
      ],
      "metadata": {
        "id": "G_H1NoGxSTHy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training procedure\n",
        "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
        "                       training_loader=training_loader, val_loader=val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF0DGyyQSkXN",
        "outputId": "0b3b887b-4799-4a33-ef3f-6cbf730f8038"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, val nll=126.04091099330357\n",
            "saved!\n",
            "Epoch: 1, val nll=113.73770368303572\n",
            "saved!\n",
            "Epoch: 2, val nll=112.10232561383928\n",
            "saved!\n",
            "Epoch: 3, val nll=111.89291782924107\n",
            "saved!\n",
            "Epoch: 4, val nll=111.95041643415179\n",
            "Epoch: 5, val nll=111.32761509486608\n",
            "saved!\n",
            "Epoch: 6, val nll=111.53196149553571\n",
            "Epoch: 7, val nll=111.49953264508929\n",
            "Epoch: 8, val nll=111.48838030133929\n",
            "Epoch: 9, val nll=111.36147739955358\n",
            "Epoch: 10, val nll=111.36245047433036\n",
            "Epoch: 11, val nll=111.24196219308035\n",
            "saved!\n",
            "Epoch: 12, val nll=111.10337751116072\n",
            "saved!\n",
            "Epoch: 13, val nll=111.11079171316965\n",
            "Epoch: 14, val nll=111.23152483258929\n",
            "Epoch: 15, val nll=111.09098772321428\n",
            "saved!\n",
            "Epoch: 16, val nll=110.8620849609375\n",
            "saved!\n",
            "Epoch: 17, val nll=110.72084123883928\n",
            "saved!\n",
            "Epoch: 18, val nll=110.241982421875\n",
            "saved!\n",
            "Epoch: 19, val nll=110.16437918526786\n",
            "saved!\n",
            "Epoch: 20, val nll=109.52483119419642\n",
            "saved!\n",
            "Epoch: 21, val nll=109.31028250558036\n",
            "saved!\n",
            "Epoch: 22, val nll=108.92828752790179\n",
            "saved!\n",
            "Epoch: 23, val nll=108.34995326450893\n",
            "saved!\n",
            "Epoch: 24, val nll=107.91611955915178\n",
            "saved!\n",
            "Epoch: 25, val nll=107.43744559151786\n",
            "saved!\n",
            "Epoch: 26, val nll=106.98549874441964\n",
            "saved!\n",
            "Epoch: 27, val nll=106.79672991071429\n",
            "saved!\n",
            "Epoch: 28, val nll=106.07344587053572\n",
            "saved!\n",
            "Epoch: 29, val nll=106.27613560267856\n",
            "Epoch: 30, val nll=105.72455984933036\n",
            "saved!\n",
            "Epoch: 31, val nll=105.77754743303572\n",
            "Epoch: 32, val nll=105.22384835379464\n",
            "saved!\n",
            "Epoch: 33, val nll=105.49541573660714\n",
            "Epoch: 34, val nll=104.87830287388392\n",
            "saved!\n",
            "Epoch: 35, val nll=104.92536272321429\n",
            "Epoch: 36, val nll=104.88427943638393\n",
            "Epoch: 37, val nll=104.93849539620535\n",
            "Epoch: 38, val nll=104.36313058035714\n",
            "saved!\n",
            "Epoch: 39, val nll=104.22018484933035\n",
            "saved!\n",
            "Epoch: 40, val nll=104.12654436383929\n",
            "saved!\n",
            "Epoch: 41, val nll=104.48727120535715\n",
            "Epoch: 42, val nll=103.98674246651785\n",
            "saved!\n",
            "Epoch: 43, val nll=104.00018973214286\n",
            "Epoch: 44, val nll=103.7544921875\n",
            "saved!\n",
            "Epoch: 45, val nll=103.65479701450893\n",
            "saved!\n",
            "Epoch: 46, val nll=103.45262416294644\n",
            "saved!\n",
            "Epoch: 47, val nll=103.5591552734375\n",
            "Epoch: 48, val nll=103.02171944754464\n",
            "saved!\n",
            "Epoch: 49, val nll=103.04505161830357\n",
            "Epoch: 50, val nll=102.94422572544643\n",
            "saved!\n",
            "Epoch: 51, val nll=102.93883370535714\n",
            "saved!\n",
            "Epoch: 52, val nll=102.46858049665178\n",
            "saved!\n",
            "Epoch: 53, val nll=102.75663853236607\n",
            "Epoch: 54, val nll=102.74367327008929\n",
            "Epoch: 55, val nll=102.84898786272322\n",
            "Epoch: 56, val nll=102.59730887276785\n",
            "Epoch: 57, val nll=102.24312151227679\n",
            "saved!\n",
            "Epoch: 58, val nll=102.1604833984375\n",
            "saved!\n",
            "Epoch: 59, val nll=102.29745884486607\n",
            "Epoch: 60, val nll=101.98698521205357\n",
            "saved!\n",
            "Epoch: 61, val nll=102.20880231584822\n",
            "Epoch: 62, val nll=102.21348214285715\n",
            "Epoch: 63, val nll=102.24545200892857\n",
            "Epoch: 64, val nll=101.89638392857142\n",
            "saved!\n",
            "Epoch: 65, val nll=101.59408063616071\n",
            "saved!\n",
            "Epoch: 66, val nll=101.898369140625\n",
            "Epoch: 67, val nll=101.83747209821429\n",
            "Epoch: 68, val nll=101.82597726004464\n",
            "Epoch: 69, val nll=101.41904715401786\n",
            "saved!\n",
            "Epoch: 70, val nll=101.73464773995536\n",
            "Epoch: 71, val nll=101.80841238839285\n",
            "Epoch: 72, val nll=101.34666085379465\n",
            "saved!\n",
            "Epoch: 73, val nll=101.39609514508929\n",
            "Epoch: 74, val nll=101.45989048549107\n",
            "Epoch: 75, val nll=101.3056982421875\n",
            "saved!\n",
            "Epoch: 76, val nll=101.42996233258928\n",
            "Epoch: 77, val nll=101.3717822265625\n",
            "Epoch: 78, val nll=101.4672265625\n",
            "Epoch: 79, val nll=101.46053641183036\n",
            "Epoch: 80, val nll=101.24738420758929\n",
            "saved!\n",
            "Epoch: 81, val nll=101.25712472098215\n",
            "Epoch: 82, val nll=101.73564522879464\n",
            "Epoch: 83, val nll=101.40933035714286\n",
            "Epoch: 84, val nll=101.32053083147322\n",
            "Epoch: 85, val nll=100.99523995535715\n",
            "saved!\n",
            "Epoch: 86, val nll=101.31197684151786\n",
            "Epoch: 87, val nll=100.86268415178571\n",
            "saved!\n",
            "Epoch: 88, val nll=101.02233607700893\n",
            "Epoch: 89, val nll=100.83278529575892\n",
            "saved!\n",
            "Epoch: 90, val nll=100.94410853794643\n",
            "Epoch: 91, val nll=100.9668505859375\n",
            "Epoch: 92, val nll=101.09479771205358\n",
            "Epoch: 93, val nll=101.18325404575893\n",
            "Epoch: 94, val nll=101.06712681361607\n",
            "Epoch: 95, val nll=100.97712472098215\n",
            "Epoch: 96, val nll=100.89202287946429\n",
            "Epoch: 97, val nll=101.15698660714285\n",
            "Epoch: 98, val nll=101.37452287946428\n",
            "Epoch: 99, val nll=101.17540806361608\n",
            "Epoch: 100, val nll=101.54486746651786\n",
            "Epoch: 101, val nll=101.36114327566965\n",
            "Epoch: 102, val nll=100.83350027901785\n",
            "Epoch: 103, val nll=101.22735700334822\n",
            "Epoch: 104, val nll=101.08365164620535\n",
            "Epoch: 105, val nll=101.35923828125\n",
            "Epoch: 106, val nll=101.14087751116071\n",
            "Epoch: 107, val nll=100.89703473772322\n",
            "Epoch: 108, val nll=101.0508203125\n",
            "Epoch: 109, val nll=101.43993791852678\n",
            "Epoch: 110, val nll=100.99784598214286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB2DQm31TLl6",
        "outputId": "651a8719-d24d-429f-e9dd-65559f80121b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
        "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
        "f.write(str(test_loss))\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK7ovSllSmCa",
        "outputId": "6d7b1aba-eff2-41e9-bb05-c188b1357aba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL LOSS: nll=96.61864032788031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curve(result_dir + name, nll_val)"
      ],
      "metadata": {
        "id": "4BRNW8XaSra-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_real(result_dir + name, test_loader)"
      ],
      "metadata": {
        "id": "tmOy_RIRTFFi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEs5ExPNTKHo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}